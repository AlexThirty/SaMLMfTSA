@article{RAE,
    author = {Zhou, Chong and Paffenroth, Randy C.},
    title = {Anomaly Detection with Robust Deep Autoencoders},
    year = {2017},
    isbn = {9781450348874},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3097983.3098052},
    doi = {10.1145/3097983.3098052},
    abstract = {Deep autoencoders, and other deep neural networks, have demonstrated their effectiveness in discovering non-linear features across many problem domains. However, in many real-world problems, large outliers and pervasive noise are commonplace, and one may not have access to clean training data as required by standard deep denoising autoencoders. Herein, we demonstrate novel extensions to deep autoencoders which not only maintain a deep autoencoders' ability to discover high quality, non-linear features but can also eliminate outliers and noise without access to any clean training data. Our model is inspired by Robust Principal Component Analysis, and we split the input data X into two parts, $X = L_{D} + S$, where $L_{D}$ can be effectively reconstructed by a deep autoencoder and $S$ contains the outliers and noise in the original data X. Since such splitting increases the robustness of standard deep autoencoders, we name our model a "Robust Deep Autoencoder (RDA)". Further, we present generalizations of our results to grouped sparsity norms which allow one to distinguish random anomalies from other types of structured corruptions, such as a collection of features being corrupted across many instances or a collection of instances having more corruptions than their fellows. Such "Group Robust Deep Autoencoders (GRDA)" give rise to novel anomaly detection approaches whose superior performance we demonstrate on a selection of benchmark problems.},
    journal = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
    pages = {665â€“674},
    numpages = {10},
    keywords = {robust deep autoencoders, group robust deep autoencoder, anomaly detection, denoising, autoencoders},
    location = {Halifax, NS, Canada},
    series = {KDD '17}
},

@article{DATA,
    title = {Unsupervised real-time anomaly detection for streaming data},
    journal = {Neurocomputing},
    volume = {262},
    pages = {134-147},
    year = {2017},
    note = {Online Real-Time Learning Strategies for Data Streams},
    issn = {0925-2312},
    doi = {https://doi.org/10.1016/j.neucom.2017.04.070},
    url = {https://www.sciencedirect.com/science/article/pii/S0925231217309864},
    author = {Subutai Ahmad and Alexander Lavin and Scott Purdy and Zuha Agha},
    keywords = {Anomaly detection, Hierarchical Temporal Memory, Streaming data, Unsupervised learning, Concept drift, Benchmark dataset},
    abstract = {We are seeing an enormous increase in the availability of streaming, time-series data. Largely driven by the rise of connected real-time data sources, this data presents technical challenges and opportunities. One fundamental capability for streaming analytics is to model each stream in an unsupervised fashion and detect unusual, anomalous behaviors in real-time. Early anomaly detection is valuable, yet it can be difficult to execute reliably in practice. Application constraints require systems to process data in real-time, not batches. Streaming data inherently exhibits concept drift, favoring algorithms that learn continuously. Furthermore, the massive number of independent streams in practice requires that anomaly detectors be fully automated. In this paper we propose a novel anomaly detection algorithm that meets these constraints. The technique is based on an online sequence memory algorithm called Hierarchical Temporal Memory (HTM). We also present results using the Numenta Anomaly Benchmark (NAB), a benchmark containing real-world data streams with labeled anomalies. The benchmark, the first of its kind, provides a controlled open-source environment for testing anomaly detection algorithms on streaming data. We present results and analysis for a wide range of algorithms on this benchmark, and discuss future challenges for the emerging field of streaming analytics.}
},

@misc{RPCA,
    doi = {10.48550/ARXIV.0912.3599},   
    url = {https://arxiv.org/abs/0912.3599},
    author = {Candes, Emmanuel J. and Li, Xiaodong and Ma, Yi and Wright, John},
    keywords = {Information Theory (cs.IT), FOS: Computer and information sciences, FOS: Computer and information sciences},
    title = {Robust Principal Component Analysis?},
    publisher = {arXiv},
    year = {2009},
    copyright = {arXiv.org perpetual, non-exclusive license}
},

@article{PROX,
    author = {Parikh, Neal},
    year = {2014},
    month = {01},
    pages = {127-239},
    title = {Proximal Algorithms},
    volume = {1},
    journal = {Foundations and Trends in Optimization},
    doi = {10.1561/2400000003}
}